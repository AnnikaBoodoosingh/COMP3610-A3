{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1147702",
   "metadata": {},
   "source": [
    "**Handling the jsonl files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a442ca5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\annik\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bigdata_a3_utils import load_compressed_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "133bf33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\annik\\Downloads\\amazon_reviews_data\\raw_review_Handmade_Products.tar.gz to C:\\Users\\annik\\Downloads\\amazon_reviews_data\\temp_9fad51ac22e54a7db4635f19e95c86a3...\n",
      "Loading dataset from C:\\Users\\annik\\Downloads\\amazon_reviews_data\\temp_9fad51ac22e54a7db4635f19e95c86a3\\raw_review_Handmade_Products...\n",
      "Cleaning up temporary directory: C:\\Users\\annik\\Downloads\\amazon_reviews_data\\temp_9fad51ac22e54a7db4635f19e95c86a3\n",
      "Review dataframe created\n",
      "Meta dataframe created\n"
     ]
    }
   ],
   "source": [
    "# Load the review dataset from .tar.gz\n",
    "review_dataset = load_compressed_dataset(r\"C:\\Users\\annik\\Downloads\\amazon_reviews_data\\raw_review_Handmade_Products.tar.gz\")\n",
    "df_reviews = review_dataset[\"full\"].to_pandas()\n",
    "print(\"Review dataframe created\")\n",
    "\n",
    "# Load the meta dataset from .jsonl\n",
    "meta_file_path = r\"C:\\Users\\annik\\Downloads\\review\\meta_Handmade_Products.jsonl\"\n",
    "with open(meta_file_path, 'r', encoding='utf-8') as f:\n",
    "    meta_data = [json.loads(line) for line in f]  # Read each line as a JSON object\n",
    "\n",
    "# Convert the meta data to a DataFrame\n",
    "df_meta = pd.DataFrame(meta_data)\n",
    "print(\"Meta dataframe created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8163315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe successfully merged!\n"
     ]
    }
   ],
   "source": [
    "# Merge datasets\n",
    "merged_df = df_reviews.merge(df_meta, how=\"left\", on=\"parent_asin\")\n",
    "print(\"Dataframe successfully merged!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6a29c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining rows: 662043\n",
      "Missing brands from details: 0\n",
      "Missing brands from store: 3299\n"
     ]
    }
   ],
   "source": [
    "# Filter reviews and clean data\n",
    "merged_df = merged_df[merged_df['rating'].between(1, 5)]\n",
    "merged_df = merged_df[merged_df['text'].notna() & (merged_df['text'].str.strip() != \"\")]\n",
    "merged_df['details'] = merged_df['details'].fillna(\"Unknown\")\n",
    "merged_df['store'] = merged_df['store'].fillna(\"Unknown\")\n",
    "\n",
    "print(\"Remaining rows:\", len(merged_df))\n",
    "print(\"Missing brands from details:\", (merged_df['details'] == 'Unknown').sum())\n",
    "print(\"Missing brands from store:\", (merged_df['store'] == 'Unknown').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a89beeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 7345 duplicate reviews\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "before = len(merged_df)\n",
    "merged_df = merged_df.drop_duplicates(subset=['user_id', 'asin', 'text'], keep='first')\n",
    "after = len(merged_df)\n",
    "print(f\"Removed {before - after} duplicate reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89fbf594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review length column created!\n"
     ]
    }
   ],
   "source": [
    "import re  \n",
    "\n",
    "# Function to compute token count in review text\n",
    "def review_length(text):\n",
    "    if isinstance(text, str):\n",
    "        tokens = re.findall(r'\\b\\w+\\b', text)\n",
    "        return len(tokens)\n",
    "    else:\n",
    "        return 0  \n",
    "    \n",
    "# Apply to create the 'review_length' column\n",
    "merged_df['review_length'] = merged_df['text'].apply(review_length)\n",
    "print(\"Review length column created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12bc48b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting timestamp column to datetime\n",
      "Year column extracted and created!\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'timestamp' column to datetime\n",
    "merged_df['timestamp'] = pd.to_datetime(merged_df['timestamp'], errors='coerce')\n",
    "print(\"Converting timestamp column to datetime\")\n",
    "\n",
    "# Extract the year\n",
    "merged_df['year'] = merged_df['timestamp'].dt.year\n",
    "merged_df[['text', 'review_length', 'timestamp', 'year']].head()\n",
    "print(\"Year column extracted and created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d8f1f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling complex columns... converting values to NaN\n"
     ]
    }
   ],
   "source": [
    "# Handling complex columns (set to NaN temporarily)\n",
    "print(\"Handling complex columns... converting values to NaN\")\n",
    "complex_cols = ['images_x', 'images_y', 'videos', 'features', 'description', 'categories']\n",
    "\n",
    "for col in complex_cols:\n",
    "    merged_df[col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a32d78c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving cleaned category...\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned dataframe as Parquet\n",
    "print(\"Saving cleaned category...\")\n",
    "merged_df.to_parquet(\"Handmade_Products_Merged.parquet\", index=False, engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b24c226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rating                                     title_x  \\\n",
      "0     5.0                            Beautiful colors   \n",
      "1     5.0  You simply must order order more than one!   \n",
      "2     5.0                                       Great   \n",
      "3     5.0                  Well made and so beautiful   \n",
      "4     5.0            Smells just like the real thing!   \n",
      "\n",
      "                                                text  images_x        asin  \\\n",
      "0  I bought one for myself and one for my grandda...       NaN  B08GPJ1MSN   \n",
      "1  Iâ€™ve ordered three bows so far. Have not been ...       NaN  B084TWHS7W   \n",
      "2  As pictured. Used a frame from the dollar stor...       NaN  B07V3NRQC4   \n",
      "3  This is beyond beautiful.  So shiny, the size ...       NaN  B071ZMDK26   \n",
      "4  Oh wow what a pleasant surprise! This smells g...       NaN  B01MPVZ4YP   \n",
      "\n",
      "  parent_asin                       user_id                     timestamp  \\\n",
      "0  B08GPJ1MSN  AF7OANMNHQJC3PD4HRPX2FATECPA 1970-01-01 00:27:01.607495111   \n",
      "1  B084TWHS7W  AGMJ3EMDVL6OWBJF7CA5RGJLXN5A 1970-01-01 00:26:27.762946965   \n",
      "2  B07V3NRQC4  AEYORY2AVPMCPDV57CE337YU5LXA 1970-01-01 00:26:31.448951297   \n",
      "3  B071ZMDK26  AEINY4XOINMMJCK5GZ3M6MMHBN6A 1970-01-01 00:25:59.438079784   \n",
      "4  B01MPVZ4YP  AGCPAPUHXYA3EEIL2KGSQTGO5HRA 1970-01-01 00:25:46.906331674   \n",
      "\n",
      "   helpful_vote  verified_purchase  ... description  price  images_y  videos  \\\n",
      "0             1               True  ...         NaN  17.99       NaN     NaN   \n",
      "1             0               True  ...         NaN  13.49       NaN     NaN   \n",
      "2             0               True  ...         NaN  14.95       NaN     NaN   \n",
      "3             2               True  ...         NaN  24.00       NaN     NaN   \n",
      "4             1               True  ...         NaN    NaN       NaN     NaN   \n",
      "\n",
      "                     store  categories  \\\n",
      "0             Crystal Vibe         NaN   \n",
      "1     Package Perfect Bows         NaN   \n",
      "2  WESTBROOK DESIGN STUDIO         NaN   \n",
      "3             KEVIN N ANNA         NaN   \n",
      "4               Beaumondes         NaN   \n",
      "\n",
      "                                             details  bought_together  \\\n",
      "0  {'Package Dimensions': '4.37 x 3.43 x 0.67 inc...             None   \n",
      "1     {'Date First Available': 'September 26, 2015'}             None   \n",
      "2  {'Package Dimensions': '14.7 x 12.4 x 0.2 inch...             None   \n",
      "3  {'Package Dimensions': '3.1 x 2.25 x 1 inches;...             None   \n",
      "4  {'Package Dimensions': '4.7 x 2.4 x 2.3 inches...             None   \n",
      "\n",
      "   review_length  year  \n",
      "0             10  1970  \n",
      "1            107  1970  \n",
      "2             11  1970  \n",
      "3             56  1970  \n",
      "4             36  1970  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the saved Parquet file into a DataFrame\n",
    "df_handmade_products = pd.read_parquet(\"Handmade_Products_Merged.parquet\", engine='fastparquet')\n",
    "\n",
    "# Print the first few rows of the DataFrame\n",
    "print(df_handmade_products.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
