{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b449f6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\annik\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bigdata_a3_utils import load_compressed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe6da628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\annik\\Downloads\\review\\raw_review_Electronics.tar.gz to C:\\Users\\annik\\Downloads\\review\\temp_a227debee69b4c52bf37954d9b96c8a3...\n",
      "Loading dataset from C:\\Users\\annik\\Downloads\\review\\temp_a227debee69b4c52bf37954d9b96c8a3\\raw_review_Electronics...\n",
      "Cleaning up temporary directory: C:\\Users\\annik\\Downloads\\review\\temp_a227debee69b4c52bf37954d9b96c8a3\n",
      "Extracting C:\\Users\\annik\\Downloads\\review\\raw_meta_Electronics.tar.gz to C:\\Users\\annik\\Downloads\\review\\temp_47288a473c5749cca1afe1b8774b585c...\n",
      "Loading dataset from C:\\Users\\annik\\Downloads\\review\\temp_47288a473c5749cca1afe1b8774b585c\\raw_meta_Electronics...\n",
      "Cleaning up temporary directory: C:\\Users\\annik\\Downloads\\review\\temp_47288a473c5749cca1afe1b8774b585c\n",
      "Loaded to pandas\n"
     ]
    }
   ],
   "source": [
    "review_dataset = load_compressed_dataset(r\"C:\\Users\\annik\\Downloads\\review\\raw_review_Electronics.tar.gz\")\n",
    "meta_dataset = load_compressed_dataset(r\"C:\\Users\\annik\\Downloads\\review\\raw_meta_Electronics.tar.gz\")\n",
    "\n",
    "df_reviews = review_dataset[\"full\"].to_pandas()\n",
    "df_meta = meta_dataset[\"full\"].to_pandas()\n",
    "print(\"Loaded to pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7774a7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex columns set to NaN\n"
     ]
    }
   ],
   "source": [
    "# Replace known complex columns with NaN\n",
    "complex_cols = ['images_x', 'images_y', 'videos', 'features', 'description', 'categories']\n",
    "for col in complex_cols:\n",
    "    if col in df_reviews.columns:\n",
    "        df_reviews[col] = np.nan\n",
    "    if col in df_meta.columns:\n",
    "        df_meta[col] = np.nan\n",
    "\n",
    "print(\"Complex columns set to NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4745bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96203010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "df_reviews[\"images\"] = df_reviews[\"images\"].apply(\n",
    "    lambda x: json.dumps(x.tolist()) if isinstance(x, np.ndarray)\n",
    "    else json.dumps(x) if not pd.isna(x)\n",
    "    else json.dumps(None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ce5b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "\n",
    "df_reviews[\"images\"] = df_reviews[\"images\"].apply(\n",
    "    lambda x: base64.b64encode(x).decode('utf-8') if isinstance(x, np.ndarray) else json.dumps(x) if not pd.isna(x) else json.dumps(None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a98d8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Assuming 'df_meta' contains the images column\n",
    "def encode_image(x):\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return base64.b64encode(x).decode('utf-8')  # Convert ndarray to Base64 string\n",
    "    return x if pd.notna(x) else None  # Handle NaN values or other cases\n",
    "\n",
    "df_meta[\"images\"] = df_meta[\"images\"].apply(encode_image)\n",
    "\n",
    "# Now you can safely save to Parquet\n",
    "df_meta.to_parquet(\"meta.parquet\", engine=\"fastparquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b95596d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Assuming 'df_reviews' contains the images\n",
    "df_reviews[\"images\"] = df_reviews[\"images\"].apply(\n",
    "    lambda x: base64.b64encode(x).decode('utf-8') if isinstance(x, np.ndarray) else json.dumps(x) if not pd.isna(x) else json.dumps(None)\n",
    ")\n",
    "\n",
    "# Now you can safely save to Parquet\n",
    "df_reviews.to_parquet(\"reviews.parquet\", engine=\"fastparquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4c8bbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               main_category  \\\n",
      "0            All Electronics   \n",
      "1            All Electronics   \n",
      "2                  Computers   \n",
      "3             AMAZON FASHION   \n",
      "4  Cell Phones & Accessories   \n",
      "\n",
      "                                               title  average_rating  \\\n",
      "0             FS-1051 FATSHARK TELEPORTER V3 HEADSET             3.5   \n",
      "1                      Ce-H22B12-S1 4Kx2K Hdmi 4Port             5.0   \n",
      "2  Digi-Tatoo Decal Skin Compatible With MacBook ...             4.5   \n",
      "3  NotoCity Compatible with Vivoactive 4 band 22m...             4.5   \n",
      "4             Motorola Droid X Essentials Combo Pack             3.8   \n",
      "\n",
      "   rating_number  features  description  price  \\\n",
      "0              6       NaN          NaN   None   \n",
      "1              1       NaN          NaN   None   \n",
      "2            246       NaN          NaN  19.99   \n",
      "3            233       NaN          NaN   9.99   \n",
      "4             64       NaN          NaN  14.99   \n",
      "\n",
      "                                              images  videos       store  \\\n",
      "0  {\"hi_res\": \"[None]\", \"large\": \"['https://m.med...     NaN   Fat Shark   \n",
      "1  {\"hi_res\": \"['https://m.media-amazon.com/image...     NaN        SIIG   \n",
      "2  {\"hi_res\": \"['https://m.media-amazon.com/image...     NaN  Digi-Tatoo   \n",
      "3  {\"hi_res\": \"['https://m.media-amazon.com/image...     NaN    NotoCity   \n",
      "4  {\"hi_res\": \"[None None None None None]\", \"larg...     NaN     Verizon   \n",
      "\n",
      "   categories                                            details parent_asin  \\\n",
      "0         NaN  {\"Date First Available\": \"August 2, 2014\", \"Ma...  B00MCW7G9M   \n",
      "1         NaN  {\"Product Dimensions\": \"0.83 x 4.17 x 2.05 inc...  B00YT6XQSE   \n",
      "2         NaN  {\"Brand\": \"Digi-Tatoo\", \"Color\": \"Fresh Marble...  B07SM135LS   \n",
      "3         NaN  {\"Date First Available\": \"May 29, 2020\", \"Manu...  B089CNGZCW   \n",
      "4         NaN  {\"Product Dimensions\": \"11.6 x 6.9 x 3.1 inche...  B004E2Z88O   \n",
      "\n",
      "  bought_together subtitle author  \n",
      "0            None     None   None  \n",
      "1            None     None   None  \n",
      "2            None     None   None  \n",
      "3            None     None   None  \n",
      "4            None     None   None  \n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Function to handle the encoding of 'images' column\n",
    "def encode_image(x):\n",
    "    if isinstance(x, dict):  # Check if it's a dictionary (which we expect in 'images')\n",
    "        # Convert the dictionary to a JSON string for serialization\n",
    "        return json.dumps(x, default=str)  # Convert dictionary to a string\n",
    "    return x  # For any other case, return the value as is\n",
    "\n",
    "# Apply the encoding function to the 'images' column\n",
    "df_meta[\"images\"] = df_meta[\"images\"].apply(encode_image)\n",
    "\n",
    "# Verify the transformation by checking the first few rows\n",
    "print(df_meta.head())\n",
    "\n",
    "# Now save the DataFrame to Parquet\n",
    "df_meta.to_parquet(\"meta.parquet\", engine=\"fastparquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e882fe1a",
   "metadata": {},
   "source": [
    "**Start Running From Here After Downloading The .parquet Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0106e8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "df_reviews_dd = dd.read_parquet(\"reviews.parquet\")\n",
    "df_meta_dd = dd.read_parquet(\"meta.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f20423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dd = df_reviews_dd.merge(df_meta_dd, how='left', on='parent_asin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d7fe50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\annik\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\dask\\_task_spec.py:755: FutureWarning: Operation between non boolean Series with different indexes will no longer return a boolean result in a future version. Cast both Series to object type to maintain the prior behavior.\n",
      "  return self.func(*new_argspec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining rows (approx): 43845749\n"
     ]
    }
   ],
   "source": [
    "# Filter ratings and non-empty text\n",
    "filtered_dd = merged_dd[merged_dd['rating'].between(1, 5)]\n",
    "filtered_dd = filtered_dd[filtered_dd['text'].notnull() & (filtered_dd['text'].str.strip() != \"\")]\n",
    "\n",
    "# Trigger computation for filtered data\n",
    "remaining_rows = filtered_dd.shape[0].compute()\n",
    "print(\"Remaining rows (approx):\", remaining_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d69461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repartition to avoid memory overflow\n",
    "filtered_dd = filtered_dd.repartition(npartitions=200)\n",
    "\n",
    "# Function to fill missing values\n",
    "def fill_missing_values(df):\n",
    "    df['details'] = df['details'].fillna(\"Unknown\")\n",
    "    df['store'] = df['store'].fillna(\"Unknown\")\n",
    "    return df\n",
    "\n",
    "# Apply map_partitions to fill missing values\n",
    "filtered_dd = filtered_dd.map_partitions(fill_missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca61d09",
   "metadata": {},
   "source": [
    "**From here is where failed due to RAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887f7eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import delayed\n",
    "\n",
    "# Function to count 'Unknown' in a single series\n",
    "def count_unknown_partition(partition):\n",
    "    return (partition == \"Unknown\").sum()\n",
    "\n",
    "missing_details_brands_total = 0\n",
    "\n",
    "for delayed_partition in filtered_dd['details'].to_delayed():\n",
    "    # Wrap the delayed partition with a custom delayed function\n",
    "    count = delayed(count_unknown_partition)(delayed_partition)\n",
    "    missing_details_brands_total += count.compute()\n",
    "\n",
    "print(\"Missing brands from details (approx):\", missing_details_brands_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1caa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_store_brands_total = 0\n",
    "\n",
    "for delayed_partition in filtered_dd['store'].to_delayed():\n",
    "    count = delayed(count_unknown_partition)(delayed_partition)\n",
    "    missing_store_brands_total += count.compute()\n",
    "\n",
    "print(\"Missing brands from store (approx):\", missing_store_brands_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782abda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dd = merged_dd.drop_duplicates(subset=['user_id', 'asin', 'text'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a169c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_length(text):\n",
    "    if isinstance(text, str):\n",
    "        return len(re.findall(r'\\b\\w+\\b', text))\n",
    "    return 0\n",
    "\n",
    "merged_dd['review_length'] = merged_dd['text'].map(review_length, meta=('text', 'int64'))\n",
    "print(\"Review length column created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e74d132",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dd['timestamp'] = dd.to_datetime(merged_dd['timestamp'], errors='coerce')\n",
    "merged_dd['year'] = merged_dd['timestamp'].dt.year\n",
    "print(\"Year column extracted and created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee869c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dd.to_parquet(\"Electronics_Merged.parquet\", engine='fastparquet', write_index=False)\n",
    "print(\"Saved to Parquet successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
